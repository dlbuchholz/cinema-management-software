@INPROCEEDINGS{Damm2001,
  author = {Werner Damm and David Harel},
  title = {{LSCs}: Breathing Life into Message Sequence Charts},
  booktitle = {Formal Methods in System Design},
  year = {2001},
  volume = {19},
  pages = {45--80},
  publisher = {Kluwer Academic Publishers},
  file = {:sources\\Damm-Harel-LSCs-2001.pdf:PDF},
  owner = {jgreen},
  timestamp = {2009.05.31}
}

@ARTICLE{Greenyer2013,
  author = {Greenyer, Joel and Molzam Sharifloo, Amir and Cordy, Maxime and Heymans,
	Patrick},
  title = {Features meet scenarios: modeling and consistency-checking scenario-based
	product line specifications},
  journal = {Requirements Engineering},
  year = {2013},
  volume = {18},
  pages = {175-198},
  number = {2},
  doi = {10.1007/s00766-013-0169-4},
  issn = {0947-3602},
  keywords = {Scenario-based specification; Product lines; Feature compositions;
	Consistency},
  language = {English},
  publisher = {Springer-Verlag}
}



@INPROCEEDINGS{Greenyer2007,
  author = {Joel Greenyer and Ekkart Kindler},
  title = {{R}econciling {TGG}s with {QVT}},
  booktitle = {Proceedings of the 10th International Conference on Model Driven
	Engineering Languages and Systems, MoDELS 2007},
  year = {2007},
  series={Lecture Notes in Computer Science},
  editor = {Engels, Gregor and Opdyke, Bill and Schmidt, Douglas C. and Weil, Frank},
  volume = {4735},
  pages = {16-30},
  publisher = {Springer Berlin Heidelberg}
}

@INPROCEEDINGS{Cordy2012,
  author = {Cordy, Maxime and Greenyer, Joel and Heymans, Patrick and Molzam
	Sharifloo, Amir},
  title = {Efficient Consistency Checking of Scenario-based Product Line Specifications},
  booktitle = {Proceedings of the 20th International Requirements Engineering Conference
	(RE 2012)},
  year = {2012},
  editor = {Mats Per Erik Heimdahl and Pete Sawyer},
  pages = {161-170},
  publisher = {IEEE}
}

@MISC{UML251,
  label = {UML251},
  author = {{Object Management Group}},
  title = {{UML 2.5.1}},
  month = {December},
  year = {2017},
  note = {{OMG} document {\ttfamily formal/2017-12-05}, \url{https://www.omg.org/spec/UML/2.5.1/}},
}


@PHDTHESIS{Greenyer2011,
  author = {Joel Greenyer},
  title = {Scenario-based Design of Mechatronic Systems},
  school = {University of Paderborn},
  year = {2011},
  address = {Paderborn},
  month = {October},
  url = {http://dups.ub.uni-paderborn.de/hs/urn/urn:nbn:de:hbz:466:2-7690}
}


@TECHREPORT{Greenyer2011a,
  author = {J. Greenyer AND J. Rieke},
  title = {An Improved Algorithm for Preventing Information Loss in Incremental
	Model Synchronization},
  institution = {Software Engineering Group, Heinz Nixdorf Institute},
  year = {2011},
  number = {tr-ri-11-324},
  url = {http://www.cs.uni-paderborn.de/uploads/tx_sibibtex/GR11_tr.pdf}
}


@MISC{UppaalTiga,
  author = {Alexandre David and others},
  title = {{Uppaal Tiga -- Uppaal for Timed Games, v0.16}},
  howpublished = {\url{http://people.cs.aau.dk/~adavid/tiga/}},
  note = {letzer Zugriff: Juni 2013}
}

@MISC{FHDWModulhabdbuchBachelor,
  author = {{FHDW Hannover}},
  title = {{Modulhandbuch Bachelor (mit Studienbeginn ab Oktober 2018)}},
  howpublished = {Interne Quelle der FHDW Hannover},
  note = {{Stand 17.2.2020}},
  year = {2018}
}

@MISC{FHDWModulhabdbuchMasterInformationEngineering,
  author = {{FHDW Hannover}},
  title = {{Modulhandbuch Master Information Engineering (Modulhandbuch HFP)}},
  howpublished = {Interne Quelle der FHDW Hannover},
  note = {{Stand Mai 2021}},
  year = {2021}
}

@book{Sutton2018,
author = {Sutton, Richard S. and Barto, Andrew G.},
title = {Reinforcement Learning: An Introduction},
year = {2018},
edition = {Second},
isbn = {0262039249},
publisher = {A Bradford Book},
address = {Cambridge, MA, USA},
abstract = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics. Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.}
}

@misc{Gebhard2021,
author = {Gebhard, Hendrik and Ziegener, Dirk},
title = {{Vom Softwaremonolithen zu Microservices: Systemumstellung am Praxisbeispiel}},
howpublished = {Heise Developer (Online), \url{https://www.heise.de/hintergrund/Vom-Softwaremonolithen-zu-Microservices-Systemumstellung-am-Praxisbeispiel-4994196.html}},
note = {letzer Zugriff: 22. Dez 2021},
year=2021
}